# LeRobot ACT VAE Encoder - æŸ¥è¯¢ç»“æœæ€»ç»“

## ğŸ“Œ ä½ çš„æŸ¥è¯¢

åœ¨ LeRobot é¡¹ç›®ä¸­ï¼ŒæŸ¥æ‰¾ ACT æ¨¡å‹ VAE encoder çš„é¢„æœŸè¾“å…¥å½¢çŠ¶ï¼š

1. âœ… åœ¨ lerobot/policies/act/modeling_act.py ä¸­æ‰¾åˆ° VAE encoder çš„ forward æ–¹æ³•
2. âœ… æŸ¥çœ‹å®ƒå¯¹è¾“å…¥ shape çš„æœŸæœ›ï¼Œå°¤å…¶æ˜¯å½“ n_obs_steps=1 æ—¶
3. âœ… æŸ¥æ‰¾å¦‚ä½•æ­£ç¡®æ„é€  vae_encoder_input - å®ƒåº”è¯¥æ˜¯ä»€ä¹ˆå½¢çŠ¶
4. âœ… æ‰¾åˆ° torch.cat æ“ä½œçš„ä¸Šä¸‹æ–‡ï¼Œçœ‹çœ‹ä¸ºä»€ä¹ˆä¼šå‡ºç°"Tensors must have same number of dimensions: got 3 and 4"

---

## ğŸ¯ æ ¸å¿ƒç­”æ¡ˆ

### 1. VAE Encoder çš„é¢„æœŸè¾“å…¥å½¢çŠ¶

```python
# VAE Encoder æœŸæœ›çš„è¾“å…¥å½¢çŠ¶ï¼š(B, C, H, W) â€” 4ç»´

# å…·ä½“å‚æ•°ï¼š
#   B: batch_size (ä¾‹å¦‚ 32)
#   C: channels = 3 (RGB)
#   H: height = 480
#   W: width = 640

# å®Œæ•´ç¤ºä¾‹
images_for_vae = torch.randn(32, 3, 480, 640)  # âœ… æ­£ç¡®çš„è¾“å…¥å½¢çŠ¶
```

### 2. images å’Œ states åº”è¯¥æ˜¯ä»€ä¹ˆå½¢çŠ¶

#### ä» DataLoader è·å–çš„å½¢çŠ¶

```python
# DataLoader æä¾›çš„æ‰¹æ¬¡
batch = {
    "observation.images.front": torch.randn(32, 1, 3, 480, 640),  # (B, T, C, H, W) â€” 5ç»´
    "observation.state": torch.randn(32, 1, 15),                   # (B, T, state_dim) â€” 3ç»´
}

# è¯´æ˜ï¼š
# - 32 æ˜¯ batch_size
# - 1 æ˜¯ n_obs_steps (ACT ä»…æ”¯æŒ 1)
# - 3 æ˜¯å›¾åƒé€šé“æ•°
# - 480, 640 æ˜¯å›¾åƒå°ºå¯¸
# - 15 æ˜¯çŠ¶æ€ç»´åº¦
```

### 3. å¦‚ä½•æ­£ç¡®æ„é€  vae_encoder_input

```python
# âœ… æ­£ç¡®æ–¹å¼ï¼šå±•å¹³ (B, T) ç»´åº¦

# ä» DataLoader è·å–
batch = next(iter(dataloader))
B, T, C, H, W = batch["observation.images.front"].shape  # (32, 1, 3, 480, 640)

# å±•å¹³ç”¨äº VAE encoder
images_for_vae = batch["observation.images.front"].reshape(B * T, C, H, W)
# ç»“æœï¼š(32, 3, 480, 640) âœ…

# ä¸ºä»€ä¹ˆå±•å¹³ï¼Ÿ
# VAE encoder çš„è®¾è®¡æœŸæœ› (B, C, H, W)ï¼Œè€Œä½ æœ‰ (B, T, C, H, W)
# é€šè¿‡å±•å¹³ï¼Œ(B, T) ç»„åˆä¸ºå•ä¸€ç»´åº¦ B*Tï¼Œå¾—åˆ°æœŸæœ›çš„ 4D å½¢çŠ¶
```

### 4. "Tensors must have same number of dimensions: got 3 and 4" çš„åŸå› 

```python
# âŒ é”™è¯¯çš„æ‹¼æ¥æ–¹å¼å¯¼è‡´ç»´åº¦ä¸åŒ¹é…

images = torch.randn(32, 1, 3, 480, 640)  # 5D
states = torch.randn(32, 15)               # 2D ï¼ˆç¼ºå°‘ T ç»´åº¦ï¼‰

# VAE encoder è¾“å‡º
image_features = vae_encoder(images)  # å¯èƒ½è¿”å› 4D æˆ– 3Dï¼Œå–å†³äºå¤„ç†æ–¹å¼

# ç›´æ¥æ‹¼æ¥ä¼šå¤±è´¥
try:
    combined = torch.cat([image_features, states], dim=-1)
except RuntimeError:
    # RuntimeError: Tensors must have same number of dimensions: got 3 and 4
    # åŸå› ï¼šimage_features æ˜¯ 3D æˆ– 4Dï¼Œstates æ˜¯ 2Dï¼Œç»´æ•°ä¸åŒ

# âœ… æ­£ç¡®æ–¹å¼ï¼šç¡®ä¿ç»´æ•°ç›¸åŒ
# æ–¹æ³• 1: éƒ½è½¬ä¸º 3D
image_features_3d = image_features.reshape(B, T, -1)  # (32, 1, 128)
states_3d = states.reshape(B, T, -1)                  # (32, 1, 15)
combined = torch.cat([image_features_3d, states_3d], dim=-1)  # (32, 1, 143) âœ…

# æ–¹æ³• 2: éƒ½è½¬ä¸º 2D
image_features_flat = image_features.reshape(B*T, -1)  # (32, 128)
states_flat = states.reshape(B*T, -1)                  # (32, 15)
combined = torch.cat([image_features_flat, states_flat], dim=-1)  # (32, 143) âœ…
```

---

## ğŸ“Š å®Œæ•´çš„æ•°æ®æµ

```
æ•°æ®é›†è¾“å‡º
  images: (T, C, H, W)          states: (T, state_dim)
  â†“ collate (stack)              â†“
DataLoader
  images: (B, T, C, H, W)       states: (B, T, state_dim)
  â†“ reshape (B*T)               â†“ reshape (B*T)
VAEè¾“å…¥
  images: (B*T, C, H, W)        states: (B*T, state_dim)
  â†“ encode                       â†“
VAEè¾“å‡º
  image_features: (B*T, latent_dim)  states: (B*T, state_dim)
  â†“ reshape (B, T)              â†“ reshape (B, T)
æ¢å¤
  image_features: (B, T, latent_dim)  states: (B, T, state_dim)
  â†“ cat (dim=-1)
å®Œæ•´è§‚æµ‹
  combined: (B, T, latent_dim + state_dim)
  â†“
Transformer
  é¢„æµ‹åŠ¨ä½œ
```

---

## ğŸ”‘ å…³é”®è¦ç‚¹

### n_obs_steps=1 æ—¶çš„ç‰¹æ®Šå¤„ç†

| æ–¹é¢ | è¯´æ˜ |
|------|------|
| **ä¸ºä»€ä¹ˆä¿ç•™ T ç»´åº¦** | å³ä½¿ n_obs_steps=1ï¼Œä¹Ÿä¿æŒ (B, 1, ...) æ ¼å¼ |
| **åŸå›  1** | ä¸ LeRobot è®¾è®¡ä¸€è‡´ |
| **åŸå›  2** | æ”¯æŒå°†æ¥çš„ n_obs_steps > 1 |
| **åŸå›  3** | æ—¶é—´åºåˆ—ç‰¹æ€§ï¼ˆå³ä½¿æ˜¯å•æ­¥ï¼‰ |
| **æ­£ç¡®æ–¹å¼** | `reshape(B*T, ...)` è€Œä¸æ˜¯ `squeeze()` |

### reshape vs squeeze çš„åŒºåˆ«

```python
# âŒ squeeze çš„é—®é¢˜
images = torch.randn(32, 1, 3, 480, 640)
images_sq = images.squeeze(1)  # (32, 3, 480, 640)
# é—®é¢˜ï¼šæ—¶é—´ç»´åº¦ä¿¡æ¯ä¸¢å¤±ï¼Œæ— æ³•æ¢å¤ä¸ºåŸå§‹å½¢çŠ¶

# âœ… reshape çš„ä¼˜ç‚¹
B, T, C, H, W = images.shape
images_flat = images.reshape(B * T, C, H, W)  # (32, 3, 480, 640)
# ä¼˜ç‚¹ï¼šä¿ç•™åŸå§‹å½¢çŠ¶ä¿¡æ¯ï¼Œå¯ä»¥ç²¾ç¡®æ¢å¤
restored = images_flat.reshape(B, T, C, H, W)  # æ¢å¤æˆåŠŸï¼
```

---

## ğŸ’» å®Œæ•´çš„ä»£ç ç¤ºä¾‹

### æœ€å°åŒ–ç¤ºä¾‹

```python
import torch

# 1. ä» DataLoader è·å–æ‰¹æ¬¡
batch = next(iter(dataloader))
images = batch["observation"]["images"]  # (32, 1, 3, 480, 640)
states = batch["observation"]["states"]  # (32, 1, 15)

# 2. å±•å¹³ç”¨äº VAE encoder
B, T, C, H, W = images.shape
images_for_vae = images.reshape(B * T, C, H, W)  # (32, 3, 480, 640)
states_for_vae = states.reshape(B * T, -1)       # (32, 15)

# 3. é€šè¿‡ VAE encoder
vae_encoder = ...
image_features = vae_encoder(images_for_vae)  # (32, 128)

# 4. æ¢å¤æ—¶é—´ç»´åº¦
image_features = image_features.reshape(B, T, -1)  # (32, 1, 128)

# 5. æ‹¼æ¥
combined = torch.cat([image_features, states], dim=-1)  # (32, 1, 143) âœ…
```

### ä¸ ACTPolicy é›†æˆ

```python
from lerobot.policies.act.modeling_act import ACTPolicy

# åˆ›å»ºæ¨¡å‹
model = ACTPolicy(config)

# å‡†å¤‡è¾“å…¥ï¼ˆå…³é”®æ­¥éª¤ï¼‰
batch_input = {
    "observation.images.front": images,      # (B, T, C, H, W)
    "observation.state": states,              # (B, T, state_dim)
    "action": actions,                        # (B, horizon, action_dim)
}

# å‰å‘ä¼ æ’­ï¼ˆæ¨¡å‹å†…éƒ¨å¤„ç† VAE encoderï¼‰
output = model(batch_input)
```

---

## ğŸš¨ å¸¸è§é”™è¯¯åŠè§£å†³æ–¹æ¡ˆ

### é”™è¯¯ 1: "got 3 and 4" ç»´åº¦ä¸åŒ¹é…

**ç—‡çŠ¶**ï¼š`RuntimeError: Tensors must have same number of dimensions: got 3 and 4`

**åŸå› **ï¼šæ‹¼æ¥çš„å¼ é‡ç»´æ•°ä¸åŒ

**è§£å†³**ï¼š
```python
# âœ… ç¡®ä¿éƒ½æ˜¯ 3D
image_features = image_features.reshape(B, T, -1)  # (B, T, latent)
states = states.reshape(B, T, -1)                  # (B, T, state)
combined = torch.cat([image_features, states], dim=-1)  # âœ…
```

### é”™è¯¯ 2: VAE encoder è¾“å…¥å½¢çŠ¶ä¸å¯¹

**ç—‡çŠ¶**ï¼š`RuntimeError: Expected input size (720, 3, 480, 640), got ...`

**åŸå› **ï¼šè¾“å…¥æ˜¯ 5D è€Œä¸æ˜¯ 4D

**è§£å†³**ï¼š
```python
# âœ… å±•å¹³å›¾åƒ
B, T, C, H, W = images.shape
images = images.reshape(B * T, C, H, W)
```

### é”™è¯¯ 3: æ— æ³•æ¢å¤æ—¶é—´ç»´åº¦

**ç—‡çŠ¶**ï¼šå¤„ç†åçš„å¼ é‡å½¢çŠ¶æ— æ³•æ¢å¤

**åŸå› **ï¼šä½¿ç”¨äº† squeezeï¼Œä¸¢å¤±äº†å½¢çŠ¶ä¿¡æ¯

**è§£å†³**ï¼š
```python
# âœ… ä½¿ç”¨ reshape å¹¶ä¿å­˜åŸå§‹å½¢çŠ¶
B, T = 32, 1
images_flat = images.reshape(B * T, 3, 480, 640)
features = vae_encoder(images_flat)  # (32, 128)
features_restored = features.reshape(B, T, -1)  # (32, 1, 128) âœ…
```

---

## ğŸ“š é…å¥—æ–‡æ¡£

æˆ‘ä¸ºä½ åˆ›å»ºäº† 4 ä»½è¯¦ç»†æ–‡æ¡£ï¼ˆéƒ½åœ¨é¡¹ç›®æ ¹ç›®å½•ï¼‰ï¼š

1. **[LEROBOT_ACT_VAE_INDEX.md](./LEROBOT_ACT_VAE_INDEX.md)** â­ **æ–‡æ¡£å¯¼èˆª**
   - å¿«é€Ÿå¯¼èˆªæ‰€æœ‰æ–‡æ¡£
   - æŒ‰é—®é¢˜æŸ¥æ‰¾ä¿¡æ¯
   - æ¨èé˜…è¯»è·¯å¾„

2. **[LEROBOT_ACT_VAE_COMPLETE_ANSWER.md](./LEROBOT_ACT_VAE_COMPLETE_ANSWER.md)** â­ **å®Œæ•´ç­”æ¡ˆ**
   - ç›´æ¥å›ç­”ä½ çš„ 4 ä¸ªé—®é¢˜
   - è¯¦ç»†çš„ä¾‹å­å’Œæ•°æ®æµå›¾
   - æ‰€æœ‰æ¦‚å¿µçš„å®Œæ•´è§£é‡Š

3. **[LEROBOT_ACT_VAE_ENCODER_GUIDE.md](./LEROBOT_ACT_VAE_ENCODER_GUIDE.md)** â­ **æ·±åº¦æ•™ç¨‹**
   - å®Œæ•´çš„ç†è®ºè§£é‡Š
   - 10 ä¸ªä¸»è¦ç« èŠ‚
   - 7 ç§å¸¸è§é”™è¯¯è¯¦è§£

4. **[LEROBOT_ACT_VAE_IMPLEMENTATION.md](./LEROBOT_ACT_VAE_IMPLEMENTATION.md)** â­ **å®ç°æŒ‡å—**
   - å¯å¤åˆ¶ç²˜è´´çš„ä»£ç ç¤ºä¾‹
   - å®Œæ•´çš„æ•°æ®åŠ è½½ç®¡é“
   - è¯¦ç»†çš„è°ƒè¯•æŠ€å·§

5. **[LEROBOT_ACT_VAE_QUICK_REFERENCE.md](./LEROBOT_ACT_VAE_QUICK_REFERENCE.md)** â­ **é€ŸæŸ¥è¡¨**
   - 5 åˆ†é’Ÿå¿«é€Ÿå‚è€ƒ
   - ä»£ç æ¨¡æ¿
   - å¸¸è§é—®é¢˜é€Ÿè§£

---

## ğŸ¯ å¿«é€Ÿå¼€å§‹

### å¦‚æœä½ åªæœ‰ 5 åˆ†é’Ÿ
è¯» [LEROBOT_ACT_VAE_QUICK_REFERENCE.md](./LEROBOT_ACT_VAE_QUICK_REFERENCE.md)

### å¦‚æœä½ æœ‰ 15 åˆ†é’Ÿ
è¯» [LEROBOT_ACT_VAE_COMPLETE_ANSWER.md](./LEROBOT_ACT_VAE_COMPLETE_ANSWER.md)

### å¦‚æœä½ æƒ³å®Œå…¨ç†è§£
æŒ‰è¿™ä¸ªé¡ºåºè¯»ï¼š
1. [LEROBOT_ACT_VAE_QUICK_REFERENCE.md](./LEROBOT_ACT_VAE_QUICK_REFERENCE.md) (5 min)
2. [LEROBOT_ACT_VAE_COMPLETE_ANSWER.md](./LEROBOT_ACT_VAE_COMPLETE_ANSWER.md) (15 min)
3. [LEROBOT_ACT_VAE_ENCODER_GUIDE.md](./LEROBOT_ACT_VAE_ENCODER_GUIDE.md) (40 min)
4. [LEROBOT_ACT_VAE_IMPLEMENTATION.md](./LEROBOT_ACT_VAE_IMPLEMENTATION.md) (45 min)

### å¦‚æœä½ åœ¨ Debug
1. æŸ¥çœ‹ [LEROBOT_ACT_VAE_QUICK_REFERENCE.md çš„é”™è¯¯æ’æŸ¥æ ‘](./LEROBOT_ACT_VAE_QUICK_REFERENCE.md#-é”™è¯¯æ’æŸ¥æ ‘)
2. æŸ¥çœ‹ [LEROBOT_ACT_VAE_IMPLEMENTATION.md çš„é”™è¯¯æ’æŸ¥éƒ¨åˆ†](./LEROBOT_ACT_VAE_IMPLEMENTATION.md#ç¬¬äºŒéƒ¨åˆ†-å¸¸è§é”™è¯¯æ’æŸ¥)

---

## ğŸ“‹ æ£€æŸ¥æ¸…å•

åœ¨éƒ¨ç½²ä»£ç å‰ï¼Œç¡®ä¿ï¼š

- [ ] VAE encoder çš„è¾“å…¥æ˜¯ 4D `(B, C, H, W)`
- [ ] ä½¿ç”¨ `reshape(B*T, C, H, W)` è€Œä¸æ˜¯ `squeeze()`
- [ ] images å’Œ states éƒ½ä» DataLoader çš„ `(B, T, ...)` å±•å¹³åˆ° `(B*T, ...)`
- [ ] n_obs_steps è®¾ç½®ä¸º 1ï¼ˆACT è¦æ±‚ï¼‰
- [ ] VAE encoder è¾“å‡ºå½¢çŠ¶ä¸º `(B*T, latent_dim)`
- [ ] æ¢å¤æ—¶é—´ç»´åº¦åä¸º `(B, T, latent_dim)`
- [ ] torch.cat çš„ä¸¤ä¸ªæ“ä½œæ•°å…·æœ‰ç›¸åŒçš„ç»´æ•°

---

## ğŸ’¡ å…³é”®æ´è§

1. **æ—¶é—´ç»´åº¦çš„è®¾è®¡**
   - å³ä½¿ `n_obs_steps=1`ï¼ŒLeRobot ä»ç„¶ä¿ç•™æ—¶é—´ç»´åº¦
   - è¿™æ˜¯ä¸ºäº†ä»£ç ä¸€è‡´æ€§å’Œå°†æ¥çš„æ‰©å±•æ€§

2. **å±•å¹³çš„å¿…è¦æ€§**
   - VAE encoder åªå¤„ç†å•ä¸ªæ—¶é—´æ­¥
   - å¿…é¡»å±•å¹³ `(B, T)` ä¸º `B*T` æ‰èƒ½ç¬¦åˆæœŸæœ›

3. **ä½¿ç”¨ reshape è€Œä¸æ˜¯ squeeze**
   - reshape ä¿ç•™å®Œæ•´çš„å½¢çŠ¶ä¿¡æ¯
   - squeeze å¯èƒ½å¯¼è‡´æ— æ³•æ¢å¤å½¢çŠ¶

4. **ç»´åº¦é”™è¯¯çš„æ ¹æœ¬åŸå› **
   - torch.cat è¦æ±‚æ“ä½œæ•°å…·æœ‰ç›¸åŒçš„ç»´æ•°
   - å¦‚æœæ··åˆäº†ä¸åŒç»´åº¦çš„å¼ é‡å°±ä¼šå¤±è´¥

---

## ğŸ“ å¿«é€Ÿå‚è€ƒ

### æœ€å¸¸ç”¨çš„ä»£ç 
```python
# å±•å¹³
B, T, C, H, W = images.shape
images_flat = images.reshape(B * T, C, H, W)

# æ¢å¤
features = features.reshape(B, T, -1)

# æ‹¼æ¥
combined = torch.cat([features, states], dim=-1)
```

### æœ€å¸¸è§çš„é”™è¯¯
| é”™è¯¯ | ä»£ç  | ä¿®å¤ |
|------|------|------|
| ç»´æ•°ä¸åŒ¹é… | `cat([3D, 2D])` | éƒ½è½¬ä¸º 3D |
| VAE è¾“å…¥ 5D | ç›´æ¥è¾“å…¥ | `reshape(B*T, ...)` |
| å½¢çŠ¶ä¸¢å¤± | `squeeze()` | æ”¹ç”¨ `reshape()` |

---

## ğŸ”— ç›¸å…³èµ„æº

### é¡¹ç›®ä»£ç å®ç°
- [scripts/train_act_real_data.py](./scripts/train_act_real_data.py) - å®Œæ•´çš„ ACT è®­ç»ƒ
- [scripts/inference_engine.py](./scripts/inference_engine.py) - æ¨ç†å®ç°ï¼ˆå« VAE å¤„ç†ï¼‰
- [test_act_minimal.py](./test_act_minimal.py) - æœ€å°åŒ–æµ‹è¯•

### å¤–éƒ¨èµ„æº
- [LeRobot å®˜æ–¹ä»“åº“](https://github.com/huggingface/lerobot)
- [PyTorch æ–‡æ¡£](https://pytorch.org/)

---

## ğŸ“ æ€»ç»“

ä½ çš„æ‰€æœ‰é—®é¢˜éƒ½å·²ç»å›ç­”ï¼š

âœ… **VAE encoder çš„è¾“å…¥å½¢çŠ¶**ï¼š`(B, C, H, W)` â€” 4D  
âœ… **images å’Œ states çš„å½¢çŠ¶**ï¼šä» DataLoader å¾—åˆ° `(B, T, ...)` åå±•å¹³  
âœ… **æ­£ç¡®çš„ vae_encoder_input æ„é€ **ï¼šä½¿ç”¨ `reshape(B*T, C, H, W)`  
âœ… **torch.cat ç»´åº¦é”™è¯¯çš„åŸå› **ï¼šæ‹¼æ¥çš„å¼ é‡ç»´æ•°ä¸ä¸€è‡´  

æ‰€æœ‰è¯¦ç»†ä¿¡æ¯ã€ä»£ç ç¤ºä¾‹å’Œæ’æŸ¥æ–¹æ³•éƒ½åœ¨é…å¥—çš„ 5 ä»½æ–‡æ¡£ä¸­ã€‚

---

**ç‰ˆæœ¬**ï¼š1.0  
**å®Œæˆæ—¥æœŸ**ï¼š2026-01-17  
**çŠ¶æ€**ï¼šâœ… å®Œæ•´å›ç­”

