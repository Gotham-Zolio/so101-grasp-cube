# LeRobot ACT VAE Encoder - å¿«é€Ÿå‚è€ƒå¡

## ğŸ¯ ä¸€å¥è¯æ€»ç»“

**ä½¿ç”¨ `reshape(B*T, C, H, W)` è€Œä¸æ˜¯ `squeeze()` æ¥å¤„ç† VAE encoder çš„è¾“å…¥ï¼**

---

## ğŸ“‹ æ ¸å¿ƒçŸ¥è¯†ç‚¹

### VAE Encoder çš„è¾“å…¥è¦æ±‚

| å†…å®¹ | è¦æ±‚ |
|------|------|
| **é¢„æœŸè¾“å…¥å½¢çŠ¶** | `(B, C, H, W)` â€” 4ç»´ |
| **æ¥è‡ª DataLoader** | `(B, T, C, H, W)` â€” 5ç»´ |
| **n_obs_steps** | **ä»…æ”¯æŒ 1**ï¼ˆACT é™åˆ¶ï¼‰|
| **å¤„ç†æ–¹å¼** | `reshape(B*T, C, H, W)` âœ… |
| **é”™è¯¯æ–¹å¼** | `squeeze(1)` âŒ |

---

## âš¡ å¿«é€Ÿä»£ç ç¤ºä¾‹

### âœ… æ­£ç¡®åšæ³•

```python
# 1. ä» DataLoader å¾—åˆ°æ‰¹æ¬¡
batch = {
    "images": torch.randn(32, 1, 3, 480, 640),  # (B, T, C, H, W)
    "states": torch.randn(32, 1, 15),            # (B, T, state_dim)
}

# 2. å±•å¹³å›¾åƒç”¨äº VAE encoder
B, T, C, H, W = batch["images"].shape
images_for_vae = batch["images"].reshape(B * T, C, H, W)  # (32, 3, 480, 640) âœ…

# 3. é€šè¿‡ VAE encoder
image_features = vae_encoder(images_for_vae)  # (32, 128)

# 4. æ¢å¤æ—¶é—´ç»´åº¦
image_features = image_features.reshape(B, T, -1)  # (32, 1, 128) âœ…

# 5. ä¸çŠ¶æ€æ‹¼æ¥
combined = torch.cat([image_features, batch["states"]], dim=-1)  # (32, 1, 143) âœ…
```

### âŒ å¸¸è§é”™è¯¯

```python
# âŒ é”™è¯¯ 1: squeeze ä¸¢å¤±ä¿¡æ¯
images_sq = batch["images"].squeeze(1)  # (32, 3, 480, 640) â€” ä¸¢å¤±æ—¶é—´ç»´åº¦

# âŒ é”™è¯¯ 2: ç›´æ¥æ‹¼æ¥é«˜ç»´å¼ é‡
torch.cat([batch["images"], batch["states"]], dim=-1)  # ç»´åº¦ä¸åŒ¹é…ï¼

# âŒ é”™è¯¯ 3: ç»´åº¦ä¸ä¸€è‡´
image_features = vae_encoder(batch["images"])  # æœŸæœ› 4D è¾“å…¥ä½†å¾—åˆ° 5D
```

---

## ğŸ“Š å½¢çŠ¶å˜æ¢è¡¨

| é˜¶æ®µ | å¼ é‡ | å½¢çŠ¶ | è¯´æ˜ |
|------|------|------|------|
| **Dataset** | images | `(T, C, H, W)` | å•ä¸ªæ ·æœ¬ |
| **DataLoader** | images | `(B, T, C, H, W)` | B=32, T=1 |
| **å±•å¹³** | images_flat | `(B*T, C, H, W)` | â† è¾“å…¥ VAE |
| **VAE è¾“å‡º** | features | `(B*T, latent)` | B*T=32 |
| **æ¢å¤æ—¶é—´** | features | `(B, T, latent)` | æ¢å¤ç»“æ„ |
| **æ‹¼æ¥** | combined | `(B, T, latent+state)` | â† è¾“å…¥ Transformer |

---

## ğŸ”§ å¸¸è§é—®é¢˜é€Ÿè§£

### Q1: ä¸ºä»€ä¹ˆä¸èƒ½ç”¨ squeeze?

```python
# squeeze(1) çš„é—®é¢˜
images = torch.randn(32, 1, 3, 480, 640)
images_sq = images.squeeze(1)  # (32, 3, 480, 640)

# æ—¶é—´ç»´åº¦ä¿¡æ¯ä¸¢å¤±ï¼Œæ— æ³•æ¢å¤ä¸ºåŸå§‹çš„ (B, T, C, H, W)
# è€Œ reshape ä¿ç•™äº†æ‰€æœ‰ä¿¡æ¯
images_flat = images.reshape(32 * 1, 3, 480, 640)  # (32, 3, 480, 640)
images_restored = images_flat.reshape(32, 1, 3, 480, 640)  # âœ… æ¢å¤æˆåŠŸ
```

### Q2: ä¸ºä»€ä¹ˆè¦å±•å¹³?

```
VAE Encoder çš„è®¾è®¡ï¼š
  - æœŸæœ›ï¼š(B, C, H, W) â€” 4D
  - ä½ æœ‰ï¼š(B, T, C, H, W) â€” 5D
  
è§£å†³æ–¹æ¡ˆï¼š
  - å°† (B, T) ç»„åˆä¸ºå•ä¸€ç»´åº¦ B*T
  - å¾—åˆ° (B*T, C, H, W) â€” 4D
  - å¤„ç†åæ¢å¤åŸå§‹ç»“æ„
```

### Q3: n_obs_steps åªæ”¯æŒ 1 ä¸ºä»€ä¹ˆè¿˜è¦ç»´æŠ¤ T ç»´åº¦?

```python
# åŸå›  1: ä»£ç å…¼å®¹æ€§
# å¦‚æœæœªæ¥æ”¯æŒ n_obs_steps > 1ï¼Œä»£ç æ— éœ€æ”¹åŠ¨
images = torch.randn(32, 1, 3, 480, 640)  # ç°åœ¨æ”¯æŒ
images = torch.randn(32, 2, 3, 480, 640)  # å°†æ¥å¯èƒ½æ”¯æŒ

# åŸå›  2: ä¸ ACT è®¾è®¡ä¸€è‡´
# ACT çš„æ•°æ®æµä¿ç•™æ—¶é—´ç»´åº¦ï¼Œå³ä½¿æ˜¯ 1
```

### Q4: ä¸ºä»€ä¹ˆä¼šå‡ºç° "got 3 and 4" é”™è¯¯?

```python
# è¿™ä¸ªé”™è¯¯ï¼štorch.cat([A, B], dim=-1) ä¸­ A å’Œ B ç»´æ•°ä¸åŒ

# âŒ é”™è¯¯çš„æ‹¼æ¥
image_features = torch.randn(32, 1, 128)  # 3D
states = torch.randn(32, 15)               # 2D â† ç»´æ•°ä¸åŒï¼
torch.cat([image_features, states], dim=-1)  # RuntimeError

# âœ… æ­£ç¡®çš„æ‹¼æ¥
image_features = torch.randn(32, 1, 128)  # 3D
states = torch.randn(32, 1, 15)            # 3D â† ç»´æ•°ç›¸åŒï¼
torch.cat([image_features, states], dim=-1)  # (32, 1, 143) âœ…
```

---

## ğŸ¬ å®Œæ•´å·¥ä½œæµ

```python
# 1ï¸âƒ£ DataLoader è¾“å‡º
batch = next(iter(dataloader))
images = batch["observation"]["images"]  # (B, T, C, H, W)
states = batch["observation"]["states"]  # (B, T, state_dim)

# 2ï¸âƒ£ å±•å¹³
B, T, C, H, W = images.shape
images_flat = images.reshape(B * T, C, H, W)  # (B*T, C, H, W)
states_flat = states.reshape(B * T, -1)       # (B*T, state_dim)

# 3ï¸âƒ£ VAE Encoder
image_features = vae_encoder(images_flat)  # (B*T, latent_dim)

# 4ï¸âƒ£ æ¢å¤æ—¶é—´ç»´åº¦
image_features = image_features.reshape(B, T, -1)  # (B, T, latent_dim)

# 5ï¸âƒ£ ä¸çŠ¶æ€æ‹¼æ¥
combined = torch.cat([image_features, states], dim=-1)  # (B, T, latent+state) âœ…

# 6ï¸âƒ£ ä¼ é€’ç»™ Transformer
output = transformer(combined)  # å¤„ç†å®Œæ•´çš„è§‚æµ‹
```

---

## ğŸ’¾ æ•°æ®ç»“æ„æ€»ç»“

### Dataset `__getitem__` è¿”å›

```python
{
    "observation": {
        "images": np.ndarray,  # shape (n_obs_steps, 3, 480, 640)
        "states": np.ndarray,  # shape (n_obs_steps, 15)
    },
    "action": np.ndarray,      # shape (8, 6)
}
```

### DataLoader è¾“å‡º

```python
{
    "observation": {
        "images": torch.Tensor,  # shape (B, n_obs_steps, 3, 480, 640)
        "states": torch.Tensor,  # shape (B, n_obs_steps, 15)
    },
    "action": torch.Tensor,      # shape (B, 8, 6)
}
```

### VAE Encoder è¾“å…¥

```python
# å±•å¹³ç‰ˆæœ¬
{
    "images": torch.Tensor,  # shape (B*T, 3, 480, 640)  â† 4D
    "states": torch.Tensor,  # shape (B*T, 15)           â† 2D
}
```

---

## ğŸš¨ é”™è¯¯æ’æŸ¥æ ‘

```
é”™è¯¯ï¼šRuntimeError: Tensors must have same number of dimensions: got 3 and 4

â”œâ”€ æ£€æŸ¥ image_features çš„ç»´åº¦
â”‚  â””â”€ å¦‚æœæ˜¯ 4Dï¼Œéœ€è¦ reshape æˆ– squeeze
â”‚     â”œâ”€ å¦‚æœåŒ…å«æ—¶é—´ä¿¡æ¯ï¼šreshape(B, T, -1)
â”‚     â””â”€ å¦‚æœä¸åŒ…å«ï¼šsqueeze()
â”‚
â”œâ”€ æ£€æŸ¥ states çš„ç»´åº¦
â”‚  â””â”€ ç¡®ä¿ä¸ image_features ç»´æ•°ç›¸åŒ
â”‚
â””â”€ å¦‚æœç»´æ•°ç›¸åŒï¼Œæ£€æŸ¥æ‹¼æ¥è½´
   â””â”€ torch.cat([A, B], dim=-1) çš„ A å’Œ B åº”è¯¥æœ‰ç›¸åŒçš„ç»´æ•°
```

---

## ğŸ“Œ è®°ä½è¿™ä¸ª

| æ“ä½œ | è¾“å…¥ | è¾“å‡º | ä½•æ—¶ç”¨ |
|------|------|------|--------|
| **reshape** | `(B, T, C, H, W)` | `(B*T, C, H, W)` | âœ… å¤„ç† VAE è¾“å…¥ |
| **squeeze** | `(B, 1, C, H, W)` | `(B, C, H, W)` | âŒ é¿å…ä½¿ç”¨ |
| **stack** | list of (T, ...) | `(B, T, ...)` | âœ… collate æ—¶ä½¿ç”¨ |
| **cat** | `(B, T, A)`, `(B, T, B)` | `(B, T, A+B)` | âœ… æ‹¼æ¥ç‰¹å¾ |

---

## ğŸ“ å­¦ä¹ èµ„æº

1. **æœ¬é¡¹ç›®æ–‡æ¡£**ï¼š
   - [LEROBOT_ACT_VAE_ENCODER_GUIDE.md](./LEROBOT_ACT_VAE_ENCODER_GUIDE.md) â€” è¯¦ç»†æŒ‡å—
   - [LEROBOT_ACT_VAE_IMPLEMENTATION.md](./LEROBOT_ACT_VAE_IMPLEMENTATION.md) â€” ä»£ç å®ç°

2. **é¡¹ç›®ä»£ç **ï¼š
   - [scripts/train_act_real_data.py](./scripts/train_act_real_data.py) â€” å®Œæ•´è®­ç»ƒè„šæœ¬
   - [scripts/inference_engine.py](./scripts/inference_engine.py) â€” æ¨ç†å®ç°
   - [test_act_minimal.py](./test_act_minimal.py) â€” æœ€å°åŒ–æµ‹è¯•

3. **å¤–éƒ¨èµ„æº**ï¼š
   - [LeRobot å®˜æ–¹ä»“åº“](https://github.com/huggingface/lerobot)
   - PyTorch æ–‡æ¡£

---

## âœ… éƒ¨ç½²æ£€æŸ¥æ¸…å•

åœ¨ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²å‰ï¼Œç¡®ä¿ï¼š

- [ ] æ‰€æœ‰è¾“å…¥å¼ é‡çš„å½¢çŠ¶å·²éªŒè¯
- [ ] ä½¿ç”¨ `reshape()` è€Œä¸æ˜¯ `squeeze()`
- [ ] æ—¶é—´ç»´åº¦å§‹ç»ˆä¿ç•™ä¸ºç»´åº¦ 1
- [ ] n_obs_steps è®¾ç½®ä¸º 1ï¼ˆACT è¦æ±‚ï¼‰
- [ ] torch.cat çš„æ“ä½œæ•°å…·æœ‰ç›¸åŒçš„ç»´æ•°
- [ ] VAE encoder è¾“å…¥æ˜¯ 4D `(B*T, C, H, W)`
- [ ] æ¢å¤åçš„ç‰¹å¾æ˜¯ 3D `(B, T, latent)`
- [ ] æ‹¼æ¥åçš„ç»“æœæ˜¯ 3D `(B, T, combined_dim)`

---

**ç‰ˆæœ¬**ï¼š1.0  
**æœ€åæ›´æ–°**ï¼š2026-01-17  
**ç»´æŠ¤è€…**ï¼šSo101 é¡¹ç›®

